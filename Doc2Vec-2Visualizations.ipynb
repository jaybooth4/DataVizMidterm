{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import all the dependencies\n",
    "import gensim\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from gensim import corpora, models\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now create a list that contains the name of all the text file in your data #folder\n",
    "\n",
    "docLabels = []\n",
    "docLabels = [f for f in os.listdir(\"sampletexts/\") if \n",
    " f.endswith(\".txt\")]\n",
    "#comp is for visualization 2\n",
    "compLabel = []\n",
    "compLabel = [f for f in os.listdir(\"testtext/\") if \n",
    " f.endswith(\".txt\")]\n",
    "\n",
    "#create a list data that stores the content of all text files in order of their names in docLabels\n",
    "\n",
    "data = []\n",
    "for doc in docLabels:\n",
    "    data.append(open('sampletexts/' + doc).read())\n",
    "cdata = []\n",
    "for doc in compLabel:\n",
    "    cdata.append(open('testtext/' + doc).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopword_set = set(stopwords.words('english'))\n",
    "\n",
    "#This function does all cleaning of data using two objects above\n",
    "\n",
    "def nlp_clean(data):\n",
    "\n",
    "    new_data = []\n",
    "    for d in data:\n",
    "        new_str = d.lower()\n",
    "        dlist = tokenizer.tokenize(new_str)\n",
    "        dlist = list(set(dlist).difference(stopword_set))\n",
    "        new_data.append(dlist)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collects all documents from passed list doc_list and corresponding label_list and returns an iterator over those documents\n",
    "class LabeledLineSentence(object):\n",
    "\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "              yield gensim.models.doc2vec.LabeledSentence(doc,    \n",
    "[self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docLabels are all the documents and data is the corresponding data\n",
    "data = nlp_clean(data)\n",
    "cdata = nlp_clean(cdata)\n",
    "#iterator returned over all documents\n",
    "it = LabeledLineSentence(data, docLabels)\n",
    "cit = LabeledLineSentence(cdata, compLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jefferson-notes-on-virginia.txt']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalArgs=0\n",
    "for i in data:\n",
    "    totalArgs=totalArgs+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "npdata=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['compared',\n",
       " 'also',\n",
       " 'occurs',\n",
       " 'external',\n",
       " 'regularity',\n",
       " 'kineseis',\n",
       " 'requires',\n",
       " 'times',\n",
       " 'resembles',\n",
       " 'explains',\n",
       " 'beginning',\n",
       " 'implies',\n",
       " 'difference',\n",
       " 'dealing',\n",
       " 'eye',\n",
       " 'remember',\n",
       " 'lapse',\n",
       " 'perceiving',\n",
       " 'stated',\n",
       " 'initio',\n",
       " 'scientific',\n",
       " 'thrown',\n",
       " 'infants',\n",
       " 'presentation',\n",
       " 'else',\n",
       " 'call',\n",
       " 'continuous',\n",
       " 'concurrent',\n",
       " 'seeing',\n",
       " 'even',\n",
       " 'based',\n",
       " 'frequency',\n",
       " 'concerned',\n",
       " 'attempts',\n",
       " 'path',\n",
       " 'animals',\n",
       " 'find',\n",
       " 'well',\n",
       " 'consciousness',\n",
       " 'happens',\n",
       " 'within',\n",
       " 'weight',\n",
       " 'besides',\n",
       " 'unconsciously',\n",
       " 'established',\n",
       " 'whereas',\n",
       " 'easy',\n",
       " 'recovers',\n",
       " 'includes',\n",
       " 'actualization',\n",
       " 'purpose',\n",
       " 'antecedent',\n",
       " 'use',\n",
       " 'acquired',\n",
       " 'remembers',\n",
       " 'place',\n",
       " 'otherwise',\n",
       " 'originally',\n",
       " 'involved',\n",
       " 'shall',\n",
       " 'frequent',\n",
       " 'introductory',\n",
       " 'method',\n",
       " 'towards',\n",
       " 'vigorous',\n",
       " 'day',\n",
       " 'sayings',\n",
       " 'incidental',\n",
       " 'truly',\n",
       " 'work',\n",
       " 'finally',\n",
       " 'experiencing',\n",
       " 'secondly',\n",
       " 'strenuous',\n",
       " 'frayed',\n",
       " 'concurrently',\n",
       " 'comprise',\n",
       " 'obliviscence',\n",
       " 'contrary',\n",
       " 'thought',\n",
       " 'humming',\n",
       " 'impulse',\n",
       " 'badly',\n",
       " 'soft',\n",
       " 'last',\n",
       " 'past',\n",
       " 'although',\n",
       " 'form',\n",
       " 'genesis',\n",
       " 'connexion',\n",
       " 'necessary',\n",
       " 'translated',\n",
       " 'substrate',\n",
       " 'tunes',\n",
       " 'together',\n",
       " 'determination',\n",
       " 'neither',\n",
       " 'due',\n",
       " 'respect',\n",
       " 'implanted',\n",
       " 'solely',\n",
       " 'absolute',\n",
       " 'kinds',\n",
       " 'manifestly',\n",
       " 'whereof',\n",
       " 'space',\n",
       " 'knows',\n",
       " '350',\n",
       " 'qualification',\n",
       " 'formal',\n",
       " 'process',\n",
       " 'indeed',\n",
       " 'acts',\n",
       " 'movements',\n",
       " 'comparatively',\n",
       " 'succeed',\n",
       " 'yet',\n",
       " 'ab',\n",
       " 'residual',\n",
       " 'customarily',\n",
       " 'communis',\n",
       " 'remembered',\n",
       " 'sometimes',\n",
       " 'probably',\n",
       " 'imprinted',\n",
       " 'differs',\n",
       " 'angry',\n",
       " 'anamnesis',\n",
       " 'sought',\n",
       " 'human',\n",
       " 'geometrical',\n",
       " 'running',\n",
       " 'set',\n",
       " 'recollection',\n",
       " 'less',\n",
       " 'upper',\n",
       " 'capable',\n",
       " 'difficulty',\n",
       " 'invariably',\n",
       " 'great',\n",
       " 'end',\n",
       " 'except',\n",
       " 'started',\n",
       " 'identical',\n",
       " 'saw',\n",
       " 'succeeds',\n",
       " 'unable',\n",
       " 'majority',\n",
       " 'reawaken',\n",
       " 'learned',\n",
       " 'mistakes',\n",
       " 'treat',\n",
       " 'perception',\n",
       " 'presented',\n",
       " 'stamps',\n",
       " 'customary',\n",
       " 'make',\n",
       " 'consideration',\n",
       " 'facts',\n",
       " 'ways',\n",
       " 'venture',\n",
       " 'prohibited',\n",
       " 'law',\n",
       " 'elapsed',\n",
       " 'way',\n",
       " 'since',\n",
       " 'believe',\n",
       " 'implied',\n",
       " 'bear',\n",
       " 'katholou',\n",
       " 'twice',\n",
       " 'painting',\n",
       " 'using',\n",
       " 'opposites',\n",
       " 'soonest',\n",
       " 'investigation',\n",
       " 'happened',\n",
       " 'performance',\n",
       " 'truths',\n",
       " 'let',\n",
       " 'remain',\n",
       " 'learns',\n",
       " 'witted',\n",
       " 'series',\n",
       " 'merely',\n",
       " 'particular',\n",
       " 'presentations',\n",
       " 'idea',\n",
       " 'become',\n",
       " 'disappeared',\n",
       " 'absolutely',\n",
       " 'perceives',\n",
       " 'desires',\n",
       " 'required',\n",
       " 'imply',\n",
       " 'previous',\n",
       " 'experiences',\n",
       " 'derived',\n",
       " 'exact',\n",
       " 'serve',\n",
       " 'powerfully',\n",
       " 'intelligence',\n",
       " 'somehow',\n",
       " 'stucco',\n",
       " 'properly',\n",
       " 'seek',\n",
       " 'straight',\n",
       " 'memory',\n",
       " 'help',\n",
       " 'swiftly',\n",
       " 'particularly',\n",
       " 'seal',\n",
       " 'repeatedly',\n",
       " 'draw',\n",
       " 'relearning',\n",
       " 'though',\n",
       " 'former',\n",
       " 'may',\n",
       " 'instead',\n",
       " 'ask',\n",
       " 'similarly',\n",
       " 'motion',\n",
       " 'surface',\n",
       " 'role',\n",
       " 'distinguished',\n",
       " 'structure',\n",
       " 'upon',\n",
       " 'bad',\n",
       " 'state',\n",
       " 'recover',\n",
       " 'mind',\n",
       " 'sphere',\n",
       " 'objectively',\n",
       " 'relates',\n",
       " 'proves',\n",
       " 'objective',\n",
       " 'analogous',\n",
       " 'naturally',\n",
       " 'quick',\n",
       " 'constructs',\n",
       " 'wholly',\n",
       " 'cannot',\n",
       " 'effort',\n",
       " 'nothing',\n",
       " 'suggest',\n",
       " 'distance',\n",
       " 'without',\n",
       " 'realm',\n",
       " 'mode',\n",
       " 'successful',\n",
       " 'temporal',\n",
       " 'respectively',\n",
       " 'never',\n",
       " 'occurrence',\n",
       " 'ought',\n",
       " 'loci',\n",
       " 'z',\n",
       " 'strongly',\n",
       " 'sc',\n",
       " 'recollects',\n",
       " 'intended',\n",
       " 'intuition',\n",
       " 'decay',\n",
       " 'incidentally',\n",
       " 'firstly',\n",
       " 'us',\n",
       " 'among',\n",
       " 'searching',\n",
       " 'application',\n",
       " 'granted',\n",
       " 'doubt',\n",
       " 'demonstrations',\n",
       " 'remembering',\n",
       " 'large',\n",
       " 'passion',\n",
       " 'belongs',\n",
       " 'mere',\n",
       " 'numerical',\n",
       " 'kind',\n",
       " 'continue',\n",
       " 'sees',\n",
       " 'possible',\n",
       " 'keep',\n",
       " 'cause',\n",
       " 'case',\n",
       " 'processes',\n",
       " 'whose',\n",
       " 'start',\n",
       " '1',\n",
       " 'viz',\n",
       " 'already',\n",
       " 'effected',\n",
       " 'discovers',\n",
       " 'apart',\n",
       " 'whether',\n",
       " 'stop',\n",
       " 'learn',\n",
       " 'thinking',\n",
       " 'anger',\n",
       " 'nevertheless',\n",
       " 'moment',\n",
       " 'observed',\n",
       " 'formerly',\n",
       " 'forgotten',\n",
       " 'inveterate',\n",
       " 'image',\n",
       " 'bc',\n",
       " 'divination',\n",
       " 'rule',\n",
       " 'investigate',\n",
       " 'notion',\n",
       " 'supposes',\n",
       " 'concluding',\n",
       " 'perceived',\n",
       " 'opinion',\n",
       " 'chance',\n",
       " 'sentient',\n",
       " 'seeks',\n",
       " 'un',\n",
       " 'essentially',\n",
       " 'moist',\n",
       " 'setting',\n",
       " 'speaking',\n",
       " 'first',\n",
       " 'autumn',\n",
       " 'trying',\n",
       " 'certain',\n",
       " 'regular',\n",
       " 'importance',\n",
       " 'wont',\n",
       " 'know',\n",
       " 'search',\n",
       " 'dwarf',\n",
       " 'inference',\n",
       " 'either',\n",
       " 'yesterday',\n",
       " 'actualized',\n",
       " 'shown',\n",
       " 'occurrences',\n",
       " 'small',\n",
       " 'intellect',\n",
       " 'pass',\n",
       " 'obtain',\n",
       " 'mnemonic',\n",
       " 'theory',\n",
       " 'necessarily',\n",
       " 'near',\n",
       " 'beings',\n",
       " 'need',\n",
       " 'differ',\n",
       " 'endeavours',\n",
       " 'g',\n",
       " 'mists',\n",
       " 'reach',\n",
       " 'relation',\n",
       " 'excogitate',\n",
       " 'always',\n",
       " 'likeness',\n",
       " 'discussions',\n",
       " 'supposed',\n",
       " 'upolepsis',\n",
       " 'totally',\n",
       " 'hunt',\n",
       " 'power',\n",
       " 'excites',\n",
       " 'fortuitous',\n",
       " 'air',\n",
       " 'panel',\n",
       " 'spacial',\n",
       " 'intellectual',\n",
       " 'general',\n",
       " 'pure',\n",
       " 'many',\n",
       " 'stimulation',\n",
       " 'declared',\n",
       " 'doubting',\n",
       " 'condicio',\n",
       " 'desired',\n",
       " 'young',\n",
       " 'absent',\n",
       " 'view',\n",
       " 'fits',\n",
       " 'means',\n",
       " 'exercise',\n",
       " 'denoted',\n",
       " 'length',\n",
       " 'teacher',\n",
       " 'deliberation',\n",
       " 'might',\n",
       " 'distances',\n",
       " 'deflects',\n",
       " 'j',\n",
       " 'impression',\n",
       " 'hard',\n",
       " 'equally',\n",
       " 'distinguishes',\n",
       " 'feeling',\n",
       " 'proportionate',\n",
       " 'zh',\n",
       " 'consequence',\n",
       " 'act',\n",
       " 'appertains',\n",
       " 'subsequently',\n",
       " 'assertion',\n",
       " 'single',\n",
       " 'classes',\n",
       " 'stands',\n",
       " 'cognition',\n",
       " 'equal',\n",
       " 'excel',\n",
       " 'mortal',\n",
       " 'considered',\n",
       " 'function',\n",
       " 'likewise',\n",
       " 'follows',\n",
       " 'texture',\n",
       " 'appears',\n",
       " 'around',\n",
       " 'good',\n",
       " 'white',\n",
       " 'reason',\n",
       " 'none',\n",
       " 'oreus',\n",
       " 'takes',\n",
       " 'interval',\n",
       " 'whenever',\n",
       " 'simultaneously',\n",
       " 'proceeds',\n",
       " 'moving',\n",
       " 'construct',\n",
       " 'advanced',\n",
       " 'discerns',\n",
       " 'seeking',\n",
       " 'beare',\n",
       " 'faculty',\n",
       " 'pronouncing',\n",
       " 'next',\n",
       " 'class',\n",
       " 'objects',\n",
       " 'thus',\n",
       " 'figures',\n",
       " 'missed',\n",
       " 'continued',\n",
       " 'sensory',\n",
       " 'original',\n",
       " 'starts',\n",
       " 'sensus',\n",
       " 'cognizes',\n",
       " 'control',\n",
       " 'different',\n",
       " 'ba',\n",
       " 'accordance',\n",
       " 'distinction',\n",
       " 'conceive',\n",
       " 'opposite',\n",
       " 'definition',\n",
       " 'involves',\n",
       " 'follow',\n",
       " 'easily',\n",
       " 'acquire',\n",
       " 'fundamental',\n",
       " 'resting',\n",
       " 'two',\n",
       " 'think',\n",
       " 'custom',\n",
       " 'ag',\n",
       " 'better',\n",
       " 'point',\n",
       " 'possess',\n",
       " 'magnitude',\n",
       " 'produce',\n",
       " 'empirical',\n",
       " 'want',\n",
       " 'tries',\n",
       " 'efforts',\n",
       " 'occurred',\n",
       " 'water',\n",
       " 'simply',\n",
       " 'see',\n",
       " 'proof',\n",
       " 'obviously',\n",
       " 'proportional',\n",
       " 'organs',\n",
       " 'antipheron',\n",
       " 'aforesaid',\n",
       " 'accustomed',\n",
       " 'hand',\n",
       " 'triangle',\n",
       " 'terms',\n",
       " 'sine',\n",
       " 'words',\n",
       " 'conclude',\n",
       " 'ethized',\n",
       " 'forbidden',\n",
       " 'stimulating',\n",
       " 'determinate',\n",
       " 'visual',\n",
       " 'contiguous',\n",
       " 'strictly',\n",
       " 'conceived',\n",
       " 'come',\n",
       " 'contained',\n",
       " 'quantitative',\n",
       " 'sort',\n",
       " 'concur',\n",
       " 'one',\n",
       " 'word',\n",
       " 'counter',\n",
       " 'similar',\n",
       " 'terrified',\n",
       " 'formed',\n",
       " 'discover',\n",
       " 'chronologically',\n",
       " 'l',\n",
       " 'despite',\n",
       " 'corporeal',\n",
       " 'stone',\n",
       " 'corresponding',\n",
       " 'future',\n",
       " 'organ',\n",
       " 'conception',\n",
       " 'whereby',\n",
       " 'arises',\n",
       " 'constructing',\n",
       " 'name',\n",
       " 'undergone',\n",
       " 'seat',\n",
       " 'aistheta',\n",
       " 'take',\n",
       " 'perceive',\n",
       " 'apply',\n",
       " 'k',\n",
       " 'mental',\n",
       " 'direction',\n",
       " 'nay',\n",
       " 'primary',\n",
       " 'centre',\n",
       " 'starting',\n",
       " 'walls',\n",
       " 'clear',\n",
       " 'suffer',\n",
       " 'successive',\n",
       " 'abandon',\n",
       " 'motions',\n",
       " 'kinesis',\n",
       " 'arranged',\n",
       " 'diagram',\n",
       " 'would',\n",
       " 'regarded',\n",
       " 'relative',\n",
       " 'owing',\n",
       " 'recollect',\n",
       " 'suffering',\n",
       " 'speak',\n",
       " 'immanent',\n",
       " 'tend',\n",
       " 'figure',\n",
       " 'mistaken',\n",
       " 'going',\n",
       " 'temperament',\n",
       " 'za',\n",
       " 'actual',\n",
       " 'potentially',\n",
       " 'give',\n",
       " 'subject',\n",
       " 'aristotle',\n",
       " 'acquainted',\n",
       " 'man',\n",
       " 'excited',\n",
       " 'recollecting',\n",
       " 'alone',\n",
       " 'allayed',\n",
       " 'token',\n",
       " 'phusis',\n",
       " 'moved',\n",
       " 'old',\n",
       " 'persons',\n",
       " 'people',\n",
       " 'e',\n",
       " 'non',\n",
       " 'learner',\n",
       " 'order',\n",
       " 'seems',\n",
       " 'recognize',\n",
       " 'gd',\n",
       " 'chamber',\n",
       " 'capital',\n",
       " 'aisthesis',\n",
       " 'course',\n",
       " 'moisture',\n",
       " 'forms',\n",
       " 'things',\n",
       " 'thereby',\n",
       " 'individual',\n",
       " 'occasionally',\n",
       " 'succession',\n",
       " 'made',\n",
       " 'unless',\n",
       " 'aim',\n",
       " 'reasonable',\n",
       " 'describes',\n",
       " 'thence',\n",
       " 'expectation',\n",
       " 'still',\n",
       " 'object',\n",
       " 'regards',\n",
       " 'examine',\n",
       " 'hunts',\n",
       " 'sequence',\n",
       " 'taken',\n",
       " 'passions',\n",
       " 'implantation',\n",
       " 'dispersed',\n",
       " 'memories',\n",
       " 'unrelated',\n",
       " 'inasmuch',\n",
       " 'retentive',\n",
       " 'ratio',\n",
       " 'spring',\n",
       " 'try',\n",
       " 'answering',\n",
       " 'seen',\n",
       " 'wishes',\n",
       " 'considering',\n",
       " 'attribute',\n",
       " 'principles',\n",
       " 'fixed',\n",
       " 'true',\n",
       " 'subjects',\n",
       " 'understand',\n",
       " 'said',\n",
       " 'term',\n",
       " 'mist',\n",
       " 'infers',\n",
       " 'clever',\n",
       " 'contemplates',\n",
       " 'ta',\n",
       " 'abstracts',\n",
       " 'connected',\n",
       " 'simultaneous',\n",
       " 'reminding',\n",
       " 'onward',\n",
       " 'lips',\n",
       " 'occur',\n",
       " 'shares',\n",
       " 'sense',\n",
       " 'instant',\n",
       " 'far',\n",
       " 'melancholic',\n",
       " 'h',\n",
       " 'affection',\n",
       " 'ray',\n",
       " 'avoid',\n",
       " 'generated',\n",
       " 'completely',\n",
       " 'qua',\n",
       " '2',\n",
       " 'described',\n",
       " 'slow',\n",
       " 'geometry',\n",
       " 'lie',\n",
       " 'attracts',\n",
       " 'quantity',\n",
       " 'receiving',\n",
       " 'time',\n",
       " 'affected',\n",
       " 'best',\n",
       " 'reaching',\n",
       " 'natural',\n",
       " 'say',\n",
       " 'false',\n",
       " 'instance',\n",
       " 'fortiori',\n",
       " 'preceded',\n",
       " 'cases',\n",
       " 'soul',\n",
       " 'knowledge',\n",
       " 'nature',\n",
       " 'cognize',\n",
       " 'amount',\n",
       " 'however',\n",
       " 'swayed',\n",
       " 'somewhat',\n",
       " 'whence',\n",
       " 'blunder',\n",
       " 'perceptions',\n",
       " 'reference',\n",
       " 'heard',\n",
       " 'indeterminate',\n",
       " 'longer',\n",
       " 'quite',\n",
       " 'existence',\n",
       " 'involve',\n",
       " 'get',\n",
       " 'presents',\n",
       " 'angles',\n",
       " 'children',\n",
       " 'exerts',\n",
       " 'lower',\n",
       " 'immediately',\n",
       " 'hear',\n",
       " 'internal',\n",
       " 'portion',\n",
       " 'hardness',\n",
       " 'really',\n",
       " 'considerably',\n",
       " 'bodily',\n",
       " 'b',\n",
       " 'points',\n",
       " 'abstraction',\n",
       " 'genuinely',\n",
       " 'terror',\n",
       " 'acquisition',\n",
       " 'assistance',\n",
       " 'must',\n",
       " 'sensible',\n",
       " 'something',\n",
       " 'supervened',\n",
       " 'milk',\n",
       " 'whatever',\n",
       " 'bursts',\n",
       " 'throw',\n",
       " 'reinstatement',\n",
       " 'consequently',\n",
       " 'therefore',\n",
       " 'sudden',\n",
       " 'years',\n",
       " 'picture',\n",
       " 'prompted',\n",
       " 'greater',\n",
       " 'events',\n",
       " 'derangement',\n",
       " 'impinge',\n",
       " 'magnitudes',\n",
       " 'recovery',\n",
       " 'middle',\n",
       " 'activity',\n",
       " 'science',\n",
       " 'experienced',\n",
       " 'hence',\n",
       " 'manner',\n",
       " 'directions',\n",
       " 'rapidity',\n",
       " 'resides',\n",
       " 'pralmata',\n",
       " 'deeply',\n",
       " 'percept',\n",
       " 'presence',\n",
       " 'elicited',\n",
       " 'conceivable',\n",
       " 'another',\n",
       " 'rather',\n",
       " 'rest',\n",
       " 'experience',\n",
       " 'causes',\n",
       " 'conditioned',\n",
       " 'accordingly',\n",
       " 'painted',\n",
       " 'indeterminately',\n",
       " 'question',\n",
       " 'assume',\n",
       " 'hold',\n",
       " 'present',\n",
       " 'exercises',\n",
       " 'drawn',\n",
       " 'reply',\n",
       " 'proved',\n",
       " 'requisite',\n",
       " 'doubtless',\n",
       " 'faculties',\n",
       " 'opposition',\n",
       " 'material',\n",
       " 'remnant',\n",
       " 'flux',\n",
       " 'assumes',\n",
       " 'actually',\n",
       " 'envisages',\n",
       " 'thinks',\n",
       " 'symbols',\n",
       " 'body',\n",
       " 'parts',\n",
       " 'wants',\n",
       " 'move',\n",
       " 'part',\n",
       " 'others',\n",
       " 'able',\n",
       " 'ratios',\n",
       " 'season',\n",
       " 'contemplating',\n",
       " 'brought',\n",
       " 'endowed',\n",
       " 'contemplation',\n",
       " 'reminiscence',\n",
       " 'impress',\n",
       " 'discomfort',\n",
       " 'weak',\n",
       " 'exists',\n",
       " 'right',\n",
       " 'sequel',\n",
       " 'ground',\n",
       " 'related',\n",
       " 'especially',\n",
       " 'life',\n",
       " 'like',\n",
       " 'preserving',\n",
       " 'phantasms',\n",
       " 'thing',\n",
       " 'fact',\n",
       " 'effect',\n",
       " 'dwarfs',\n",
       " 'suppose',\n",
       " 'comes',\n",
       " 'frequently',\n",
       " 'impossible',\n",
       " 'contemplate',\n",
       " 'resolve',\n",
       " 'directly',\n",
       " 'add',\n",
       " 'found',\n",
       " 'asked',\n",
       " 'smaller',\n",
       " 'rapid',\n",
       " 'given',\n",
       " 'person',\n",
       " 'changes',\n",
       " 'tends',\n",
       " 'psychically',\n",
       " 'defective',\n",
       " 'several',\n",
       " 'movement',\n",
       " 'receives',\n",
       " 'determinateness',\n",
       " 'sets',\n",
       " 'noeta',\n",
       " 'often',\n",
       " 'distant',\n",
       " 'persists',\n",
       " 'latter',\n",
       " 'example',\n",
       " 'abnormally',\n",
       " 'conversely',\n",
       " 'impressed',\n",
       " 'occurring',\n",
       " 'growth',\n",
       " 'koriskos',\n",
       " 'condition',\n",
       " 'full',\n",
       " 'actualizations',\n",
       " 'direct',\n",
       " 'determinately']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npdata[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec Training and save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\gensim\\models\\doc2vec.py:366: UserWarning:\n",
      "\n",
      "The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n",
      "iteration 100\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "d2vSize = 300\n",
    "model = gensim.models.Doc2Vec(size=d2vSize, min_count=0, alpha=0.025, min_alpha=0.025)\n",
    "model.build_vocab(it)\n",
    "\n",
    "#training of model\n",
    "for epoch in range(100):\n",
    " print ('iteration ' + str(epoch+1))\n",
    " model.train(it, total_examples = totalArgs, epochs=model.epochs)\n",
    " model.alpha -= 0.002\n",
    " model.min_alpha = model.alpha\n",
    "\n",
    "#saving the created model\n",
    "\n",
    "model.save('doc2vec.model')\n",
    "print (\"model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization 1: vector representations into PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Things I need to be passed from the back end\n",
    "#the d2v Model\n",
    "#the labels of the data\n",
    "#the size used to train the model\n",
    "#Categories to color them differently\n",
    "\n",
    "\n",
    "\n",
    "d2v_model = gensim.models.doc2vec.Doc2Vec.load('doc2vec.model')\n",
    "#put vector representations into an array\n",
    "vecArray = np.zeros(shape=(len(docLabels),d2vSize))\n",
    "for idx, labels in enumerate(docLabels):\n",
    "    vecArray[idx]=d2v_model.docvecs[labels]\n",
    "#run through PCA\n",
    "d2vPca = PCA().fit_transform(vecArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aristotle-on-263.txt', 'aristotle-on-264.txt', 'aristotle-on-265.txt', 'aristotle-on-266.txt', 'aristotle-on-267.txt', 'aristotle-on-268.txt', 'aristotle-on-269.txt', 'aristotle-on-270.txt', 'aristotle-on-271.txt', 'aristotle-on-272.txt', 'aristotle-on-273.txt', 'aristotle-on-274.txt', 'aristotle-on-275.txt', 'dickens-christmas-125.txt', 'dickens-holiday-623.txt', 'dickens-hunted-624.txt', 'plato-euthyphro-342.txt', 'plato-laws-346.txt', 'plato-philebus-352.txt', 'shakespeare-lovers-62.txt', 'shakespeare-merchant-5.txt', 'shakespeare-tempest-4.txt', 'shakespeare-two-18.txt', 'twain_tom_sawyer.txt']\n"
     ]
    }
   ],
   "source": [
    "print(docLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "hoverinfo": "text",
         "mode": "markers",
         "text": [
          "aristotle-on-263.txt",
          "aristotle-on-264.txt",
          "aristotle-on-265.txt",
          "aristotle-on-266.txt",
          "aristotle-on-267.txt",
          "aristotle-on-268.txt",
          "aristotle-on-269.txt",
          "aristotle-on-270.txt",
          "aristotle-on-271.txt",
          "aristotle-on-272.txt",
          "aristotle-on-273.txt",
          "aristotle-on-274.txt",
          "aristotle-on-275.txt",
          "dickens-christmas-125.txt",
          "dickens-holiday-623.txt",
          "dickens-hunted-624.txt",
          "plato-euthyphro-342.txt",
          "plato-laws-346.txt",
          "plato-philebus-352.txt",
          "shakespeare-lovers-62.txt",
          "shakespeare-merchant-5.txt",
          "shakespeare-tempest-4.txt",
          "shakespeare-two-18.txt",
          "twain_tom_sawyer.txt"
         ],
         "type": "scatter",
         "uid": "8afa4065-b8b6-41e4-9624-30d738429aa1",
         "x": [
          -27.583737045146364,
          -25.745292750422294,
          -26.738235098464887,
          -12.516932000646346,
          -22.78393896758989,
          6.11860288273531,
          -20.874278722698296,
          50.36540781123765,
          29.273618060007315,
          -22.16179696248153,
          68.5140785005015,
          15.259024472119336,
          -11.655573523098026,
          -23.547608737072544,
          -31.070691372990908,
          -24.647706217201925,
          -21.047929838783762,
          111.47628509675886,
          -8.265614656360802,
          -22.046459661426816,
          -29.51228565398771,
          -30.63464744178469,
          -31.35469919093988,
          111.18041101773677
         ],
         "y": [
          -23.243075298461502,
          -17.003904740123684,
          -23.82325678526554,
          -6.241675272615906,
          -14.750689602245014,
          -9.103571281422559,
          -12.103466118163722,
          8.818206655874592,
          -11.690467955505943,
          -16.214677383098977,
          5.624195902006974,
          -5.318999198684587,
          -8.347471653849968,
          41.469762600967954,
          24.31649626445052,
          6.9242243480382335,
          -18.066035408165867,
          2.8505895978669353,
          -3.3558842169015697,
          -3.2386416367551227,
          29.43359786997768,
          30.52531476085483,
          19.548770396624835,
          2.9906581545975013
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"bf915c1f-7f84-414e-ae83-71c510d170f1\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"bf915c1f-7f84-414e-ae83-71c510d170f1\", [{\"hoverinfo\": \"text\", \"mode\": \"markers\", \"text\": [\"aristotle-on-263.txt\", \"aristotle-on-264.txt\", \"aristotle-on-265.txt\", \"aristotle-on-266.txt\", \"aristotle-on-267.txt\", \"aristotle-on-268.txt\", \"aristotle-on-269.txt\", \"aristotle-on-270.txt\", \"aristotle-on-271.txt\", \"aristotle-on-272.txt\", \"aristotle-on-273.txt\", \"aristotle-on-274.txt\", \"aristotle-on-275.txt\", \"dickens-christmas-125.txt\", \"dickens-holiday-623.txt\", \"dickens-hunted-624.txt\", \"plato-euthyphro-342.txt\", \"plato-laws-346.txt\", \"plato-philebus-352.txt\", \"shakespeare-lovers-62.txt\", \"shakespeare-merchant-5.txt\", \"shakespeare-tempest-4.txt\", \"shakespeare-two-18.txt\", \"twain_tom_sawyer.txt\"], \"x\": [-27.583737045146364, -25.745292750422294, -26.738235098464887, -12.516932000646346, -22.78393896758989, 6.11860288273531, -20.874278722698296, 50.36540781123765, 29.273618060007315, -22.16179696248153, 68.5140785005015, 15.259024472119336, -11.655573523098026, -23.547608737072544, -31.070691372990908, -24.647706217201925, -21.047929838783762, 111.47628509675886, -8.265614656360802, -22.046459661426816, -29.51228565398771, -30.63464744178469, -31.35469919093988, 111.18041101773677], \"y\": [-23.243075298461502, -17.003904740123684, -23.82325678526554, -6.241675272615906, -14.750689602245014, -9.103571281422559, -12.103466118163722, 8.818206655874592, -11.690467955505943, -16.214677383098977, 5.624195902006974, -5.318999198684587, -8.347471653849968, 41.469762600967954, 24.31649626445052, 6.9242243480382335, -18.066035408165867, 2.8505895978669353, -3.3558842169015697, -3.2386416367551227, 29.43359786997768, 30.52531476085483, 19.548770396624835, 2.9906581545975013], \"type\": \"scatter\", \"uid\": \"c323b8fd-39f2-46ea-bfd9-47847448563c\"}], {}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"bf915c1f-7f84-414e-ae83-71c510d170f1\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"bf915c1f-7f84-414e-ae83-71c510d170f1\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"bf915c1f-7f84-414e-ae83-71c510d170f1\", [{\"hoverinfo\": \"text\", \"mode\": \"markers\", \"text\": [\"aristotle-on-263.txt\", \"aristotle-on-264.txt\", \"aristotle-on-265.txt\", \"aristotle-on-266.txt\", \"aristotle-on-267.txt\", \"aristotle-on-268.txt\", \"aristotle-on-269.txt\", \"aristotle-on-270.txt\", \"aristotle-on-271.txt\", \"aristotle-on-272.txt\", \"aristotle-on-273.txt\", \"aristotle-on-274.txt\", \"aristotle-on-275.txt\", \"dickens-christmas-125.txt\", \"dickens-holiday-623.txt\", \"dickens-hunted-624.txt\", \"plato-euthyphro-342.txt\", \"plato-laws-346.txt\", \"plato-philebus-352.txt\", \"shakespeare-lovers-62.txt\", \"shakespeare-merchant-5.txt\", \"shakespeare-tempest-4.txt\", \"shakespeare-two-18.txt\", \"twain_tom_sawyer.txt\"], \"x\": [-27.583737045146364, -25.745292750422294, -26.738235098464887, -12.516932000646346, -22.78393896758989, 6.11860288273531, -20.874278722698296, 50.36540781123765, 29.273618060007315, -22.16179696248153, 68.5140785005015, 15.259024472119336, -11.655573523098026, -23.547608737072544, -31.070691372990908, -24.647706217201925, -21.047929838783762, 111.47628509675886, -8.265614656360802, -22.046459661426816, -29.51228565398771, -30.63464744178469, -31.35469919093988, 111.18041101773677], \"y\": [-23.243075298461502, -17.003904740123684, -23.82325678526554, -6.241675272615906, -14.750689602245014, -9.103571281422559, -12.103466118163722, 8.818206655874592, -11.690467955505943, -16.214677383098977, 5.624195902006974, -5.318999198684587, -8.347471653849968, 41.469762600967954, 24.31649626445052, 6.9242243480382335, -18.066035408165867, 2.8505895978669353, -3.3558842169015697, -3.2386416367551227, 29.43359786997768, 30.52531476085483, 19.548770396624835, 2.9906581545975013], \"type\": \"scatter\", \"uid\": \"c323b8fd-39f2-46ea-bfd9-47847448563c\"}], {}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"bf915c1f-7f84-414e-ae83-71c510d170f1\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = d2vPca[:, 0],\n",
    "    y = d2vPca[:, 1],\n",
    "    mode='markers',\n",
    "    text = docLabels,\n",
    "    hoverinfo = 'text'\n",
    ")\n",
    "data = [trace1]\n",
    "\n",
    "iplot(data, filename='d2vScatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization 2: take any other document and find the 5 most similar from our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Things I need from the back end\n",
    "#A document preprocessed and cleaned in the same way as the corpus\n",
    "#The label of that document\n",
    "#The d2v model\n",
    "\n",
    "\n",
    "#infer a vector of the new document\n",
    "newVec=d2v_model.infer_vector(cdata[0])\n",
    "#find the most similar 10 documents\n",
    "mostSim = d2v_model.docvecs.most_similar([newVec],topn=10)\n",
    "#convert to numpy Arr\n",
    "simArr= np.array(mostSim)\n",
    "#make each number represent the percent similarity instead difference betweein 0-1\n",
    "for idx,each in enumerate(simArr):\n",
    "    simArr[idx,1]= 100-abs(float(simArr[idx,1]))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "type": "bar",
         "uid": "3917413b-729c-4e95-9a2d-ee14d7cee626",
         "x": [
          "shakespeare-two-18.txt",
          "shakespeare-tempest-4.txt",
          "dickens-holiday-623.txt",
          "shakespeare-merchant-5.txt",
          "dickens-hunted-624.txt",
          "shakespeare-lovers-62.txt",
          "aristotle-on-265.txt",
          "aristotle-on-264.txt",
          "aristotle-on-263.txt",
          "dickens-christmas-125.txt"
         ],
         "y": [
          "67.46522188186646",
          "66.72440767288208",
          "65.69784283638",
          "63.95621299743652",
          "63.13417851924896",
          "59.04744267463684",
          "56.49769306182861",
          "55.72424232959747",
          "54.67342138290405",
          "54.604196548461914"
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Most Similar Documents to jefferson-notes-on-virginia.txt"
        }
       }
      },
      "text/html": [
       "<div id=\"6c17be53-c4bd-430e-aa5f-f0c841297cb7\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"6c17be53-c4bd-430e-aa5f-f0c841297cb7\", [{\"x\": [\"shakespeare-two-18.txt\", \"shakespeare-tempest-4.txt\", \"dickens-holiday-623.txt\", \"shakespeare-merchant-5.txt\", \"dickens-hunted-624.txt\", \"shakespeare-lovers-62.txt\", \"aristotle-on-265.txt\", \"aristotle-on-264.txt\", \"aristotle-on-263.txt\", \"dickens-christmas-125.txt\"], \"y\": [\"67.46522188186646\", \"66.72440767288208\", \"65.69784283638\", \"63.95621299743652\", \"63.13417851924896\", \"59.04744267463684\", \"56.49769306182861\", \"55.72424232959747\", \"54.67342138290405\", \"54.604196548461914\"], \"type\": \"bar\", \"uid\": \"3917413b-729c-4e95-9a2d-ee14d7cee626\"}], {\"title\": {\"text\": \"Most Similar Documents to jefferson-notes-on-virginia.txt\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"6c17be53-c4bd-430e-aa5f-f0c841297cb7\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"6c17be53-c4bd-430e-aa5f-f0c841297cb7\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"6c17be53-c4bd-430e-aa5f-f0c841297cb7\", [{\"x\": [\"shakespeare-two-18.txt\", \"shakespeare-tempest-4.txt\", \"dickens-holiday-623.txt\", \"shakespeare-merchant-5.txt\", \"dickens-hunted-624.txt\", \"shakespeare-lovers-62.txt\", \"aristotle-on-265.txt\", \"aristotle-on-264.txt\", \"aristotle-on-263.txt\", \"dickens-christmas-125.txt\"], \"y\": [\"67.46522188186646\", \"66.72440767288208\", \"65.69784283638\", \"63.95621299743652\", \"63.13417851924896\", \"59.04744267463684\", \"56.49769306182861\", \"55.72424232959747\", \"54.67342138290405\", \"54.604196548461914\"], \"type\": \"bar\", \"uid\": \"3917413b-729c-4e95-9a2d-ee14d7cee626\"}], {\"title\": {\"text\": \"Most Similar Documents to jefferson-notes-on-virginia.txt\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"6c17be53-c4bd-430e-aa5f-f0c841297cb7\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graph it\n",
    "data = [go.Bar(\n",
    "            x=simArr[:,0],\n",
    "            y=simArr[:,1]\n",
    "    )]\n",
    "layout = go.Layout(\n",
    "    title=('Most Similar Documents to ' + compLabel[0])\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename='mostSim')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# examples of what info can be pulled from doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start testing\n",
    "#printing the vector of document at index 1 in docLabels\n",
    "#docvec = d2v_model.docvecs[1]\n",
    "#print (docvec)\n",
    "#printing the vector of the file using its name\n",
    "docvec = d2v_model.docvecs['aristotle-on-275.txt'] #if string tag used in training\n",
    "print (docvec.size)\n",
    "print (docvec)\n",
    "\n",
    "#to get most similar document with similarity scores using document-index\n",
    "similar_doc = d2v_model.docvecs.most_similar(6) \n",
    "#print (similar_doc)\n",
    "\n",
    "#to get most similar document with similarity scores using document- name\n",
    "sims = d2v_model.docvecs.most_similar('aristotle-on-275.txt')\n",
    "print (sims)\n",
    "\n",
    "#to get vector of document that are not present in corpus \n",
    "#docvec = d2v_model.docvecs.infer_vector('war.txt')\n",
    "#print docvec\n",
    "\n",
    "nomatch = d2v_model.docvecs.doesnt_match(docLabels)\n",
    "print (nomatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
