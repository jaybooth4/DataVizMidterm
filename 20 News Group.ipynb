{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DOCS = 1000\n",
    "NUM_THREADS = 4\n",
    "BATCH_SIZE = NUM_DOCS/NUM_THREADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.phrases import Phrases\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Al\\\\Anaconda3\\\\envs\\\\tensorflow\\\\python.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'checksum': 'c92fd4f6640a86d5ba89eaad818a9891',\n",
       " 'description': 'The notorious collection of approximately 20,000 newsgroup posts, partitioned (nearly) evenly across 20 different newsgroups.',\n",
       " 'fields': {'data': '',\n",
       "  'id': 'original id inferred from folder name',\n",
       "  'set': \"marker of original split (possible values 'train' and 'test')\",\n",
       "  'topic': 'name of topic (20 variant of possible values)'},\n",
       " 'file_name': '20-newsgroups.gz',\n",
       " 'file_size': 14483581,\n",
       " 'license': 'not found',\n",
       " 'num_records': 18846,\n",
       " 'parts': 1,\n",
       " 'read_more': ['http://qwone.com/~jason/20Newsgroups/'],\n",
       " 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/20-newsgroups/__init__.py',\n",
       " 'record_format': 'dict'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.info(\"20-newsgroups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.56 s, sys: 54.4 ms, total: 8.62 s\n",
      "Wall time: 8.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import spacy\n",
    "\n",
    "def addStopWords(stopWords, nlp):\n",
    "    for stopWord in stopWords:\n",
    "        lexeme = nlp.vocab[stopWord]\n",
    "        lexeme.is_stop = True\n",
    "        \n",
    "def filterWords(word):\n",
    "    return word.is_alpha and not word.is_stop\n",
    "\n",
    "def convertWords(word):\n",
    "    return word.lemma_.lower()\n",
    "\n",
    "def cleanDoc(doc):\n",
    "    return list(map(convertWords, filter(filterWords, doc)))\n",
    "\n",
    "nlp = spacy.load(\"en\", disable=['tagger', 'parser', 'ner', 'textcat'])\n",
    "# Currently adding no other stop words\n",
    "addStopWords([], nlp) \n",
    "\n",
    "\n",
    "nlpCorpus = []\n",
    "for doc in nlp.pipe(corpus[:NUM_DOCS], n_threads=NUM_THREADS, batch_size=BATCH_SIZE):\n",
    "    nlpCorpus.append(doc)\n",
    "    \n",
    "cleanCorpus = list(map(lambda doc: cleanDoc(doc), nlpCorpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'andrew', 'byler', 'subject', 're', 'serbian', 'genocide', 'work', 'god', 'organization', 'freshman', 'civil', 'engineering', 'carnegie', 'mellon', 'pittsburgh', 'pa', 'lines', 'vera', 'shanti', 'noyes', 'write', 'indicate', 'believe', 'predestination', 'correct', 'believe', 'predestination', 'believe', 'choose', 'accept', 'god', 'gift', 'salvation', 'fundamental', 'difference', 'resolve', 'of', 'course', 'i', 'believe', 'predestination', '-pron-', 'biblical', 'doctrine', 'roman', 'show', 'passage', 'furthermore', 'church', 'teach', 'predestination', 'begin', 'but', 'i', 'believe', 'predestination', 'mean', 'i', 'believe', 'free', 'men', 'freely', 'choose', 'course', 'life', 'affect', 'grace', 'god', 'however', 'unlike', 'calvinists', 'jansenists', 'i', 'hold', 'grace', 'resistable', 'end', 'idiocy', 'deny', 'universal', 'save', 'god', 'timothy', 'for', 'god', 'grace', 'save', 'but', 'elect', 'foreknow', 'predestine', 'receive', 'grace', 'final', 'perserverance', 'guarantee', 'heaven', 'this', 'mean', 'grace', 'save', 'mean', 'god', 'foreknow', 'obstinacy', 'choose', 'know', 'need', 'freely', 'choose', 'hell', 'people', 'save', 'save', 'grace', 'god', 'effort', 'god', 'dispose', 'himself', 'predestine', 'saint', 'but', 'perish', 'everlasting', 'fire', 'perish', 'harden', 'heart', 'choose', 'perish', 'thus', 'deserve', 'punishment', 'reject', 'creator', 'sin', 'work', 'holy', 'spirit', 'yes', 'god', 'judge', 'mete', 'punishment', 'judgement', 'well', 'i', 'hold', 'god', 'certainly', 'give', 'everybody', 'bless', 'good', 'little', 'he', 'bless', 'life', 'he', 'bless', 'and', 'he', 'punish', 'life', 'chastise', 'purgatory', 'sin', 'every', 'sin', 'incur', 'temporal', 'punishment', 'god', 'punish', 'satisfaction', 'cf', 'samuel', 'david', 'sin', 'adultery', 'murder', 'forgive', 'punish', 'death', 'child', 'and', 'i', 'need', 'point', 'idea', 'punishment', 'god', 'judgement', 'prevelant', 'bible', 'sodom', 'gommorrah', 'moses', 'bar', 'holy', 'land', 'slaughter', 'cannanites', 'annias', 'saphira', 'jerusalem', 'ad', 'etc', 'jesus', 'stop', 'stone', 'adulterous', 'woman', 'good', 'parallel', 'go', 'stop', 'murder', 'violation', 'people', 'innocent', 'we', 'stop', 'slaughter', 'innocent', 'cf', 'proverbs', 'mean', 'christian', 'support', 'war', 'bosnia', 'involve', 'i', 'think', 'i', 'isolationist', 'disagree', 'foreign', 'adventure', 'general', 'but', 'case', 'bosnia', 'i', 'frankly', 'excuse', 'get', 'militarily', 'involve', 'war', 'blessed', 'peacemaker', 'our', 'lord', 'say', 'interventionist', 'our', 'action', 'bosnia', 'peace', 'war', 'unrelated', 'justify', 'andy', 'byler']\n",
      "from\n"
     ]
    }
   ],
   "source": [
    "print(cleanCorpus[0])\n",
    "print(cleanCorpus[0][0])\n",
    "# [print(token.text) for token in cleanCorpus[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'soc.religion.christian', 'data': 'From: db7n+@andrew.cmu.edu (D. Andrew Byler)\\nSubject: Re: Serbian genocide Work of God?\\nOrganization: Freshman, Civil Engineering, Carnegie Mellon, Pittsburgh, PA\\nLines: 61\\n\\nVera Shanti Noyes writes;\\n\\n>this is what indicates to me that you may believe in predestination.\\n>am i correct?  i do not believe in predestination -- i believe we all\\n>choose whether or not we will accept God\\'s gift of salvation to us.\\n>again, fundamental difference which can\\'t really be resolved.\\n\\nOf course I believe in Predestination.  It\\'s a very biblical doctrine as\\nRomans 8.28-30 shows (among other passages).  Furthermore, the Church\\nhas always taught predestination, from the very beginning.  But to say\\nthat I believe in Predestination does not mean I do not believe in free\\nwill.  Men freely choose the course of their life, which is also\\naffected by the grace of God.  However, unlike the Calvinists and\\nJansenists, I hold that grace is resistable, otherwise you end up with\\nthe idiocy of denying the universal saving will of God (1 Timothy 2.4). \\nFor God must give enough grace to all to be saved.  But only the elect,\\nwho he foreknew, are predestined and receive the grace of final\\nperserverance, which guarantees heaven.  This does not mean that those\\nwithout that grace can\\'t be saved, it just means that god foreknew their\\nobstinacy and chose not to give it to them, knowing they would not need\\nit, as they had freely chosen hell.\\n\\t\\t\\t\\t\\t\\t\\t  ^^^^^^^^^^^\\nPeople who are saved are saved by the grace of God, and not by their own\\neffort, for it was God who disposed them to Himself, and predestined\\nthem to become saints.  But those who perish in everlasting fire perish\\nbecause they hardened their heart and chose to perish.  Thus, they were\\ndeserving of God;s punishment, as they had rejected their Creator, and\\nsinned against the working of the Holy Spirit.\\n\\n>yes, it is up to God to judge.  but he will only mete out that\\n>punishment at the last judgement. \\n\\nWell, I would hold that as God most certainly gives everybody some\\nblessing for what good they have done (even if it was only a little),\\nfor those He can\\'t bless in the next life, He blesses in this one.  And\\nthose He will not punish in the next life, will be chastised in this one\\nor in Purgatory for their sins.  Every sin incurs some temporal\\npunishment, thus, God will punish it unless satisfaction is made for it\\n(cf. 2 Samuel 12.13-14, David\\'s sin of Adultery and Murder were\\nforgiven, but he was still punished with the death of his child.)  And I\\nneed not point out the idea of punishment because of God\\'s judgement is\\nquite prevelant in the Bible.  Sodom and Gommorrah, Moses barred from\\nthe Holy Land, the slaughter of the Cannanites, Annias and Saphira,\\nJerusalem in 70 AD, etc.\\n\\n> if jesus stopped the stoning of an adulterous woman (perhaps this is\\nnot a >good parallel, but i\\'m going to go with it anyway), why should we\\nnot >stop the murder and violation of people who may (or may not) be more\\n>innocent?\\n\\nWe should stop the slaughter of the innocent (cf Proverbs 24.11-12), but\\ndoes that mean that Christians should support a war in Bosnia with the\\nU.S. or even the U.N. involved?  I do not think so, but I am an\\nisolationist, and disagree with foreign adventures in general.  But in\\nthe case of Bosnia, I frankly see no excuse for us getting militarily\\ninvolved, it would not be a \"just war.\"  \"Blessed\" after all, \"are the\\npeacemakers\" was what Our Lord said, not the interventionists.  Our\\nactions in Bosnia must be for peace, and not for a war which is\\nunrelated to anything to justify it for us.\\n\\nAndy Byler\\n', 'id': '21408', 'set': 'train'}\n"
     ]
    }
   ],
   "source": [
    "# Need to get the generator from the dataset to use with gensim\n",
    "generator = dataset.__iter__()\n",
    "print(generator.__next__()) # example doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 536870912 1073741824 1610612735 2147483647]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "\n",
    "dictionary = Dictionary(cleanBigramCorpus)\n",
    "bow = [dictionary.doc2bow(doc) for doc in cleanBigramCorpus]\n",
    "\n",
    "tfidfModel = TfidfModel(bow)  # fit model\n",
    "tfidf = [tfidfModel[doc] for doc in bow]\n",
    "\n",
    "doc2Vec = [dictionary.doc2bow(doc) for doc in cleanBigramCorpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jaybooth/gensim-data/20-newsgroups/20-newsgroups.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5edd72f16d09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcorpusJson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/Users/jaybooth/gensim-data/20-newsgroups/20-newsgroups.gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mcorpusJson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\gzip.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"write\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jaybooth/gensim-data/20-newsgroups/20-newsgroups.gz'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import gzip\n",
    "\n",
    "corpusJson = []\n",
    "file = gzip.open(\"/Users/jaybooth/gensim-data/20-newsgroups/20-newsgroups.gz\")\n",
    "corpusJson = [json.loads(line) for line in file]\n",
    "file.close()\n",
    "print(len(corpusJson))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpusJson[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(map(lambda jsonDoc: jsonDoc[\"data\"],corpusJson))\n",
    "corpusTopics = list(map(lambda jsonDoc: jsonDoc[\"topic\"],corpusJson))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = []\n",
    "for stopword in my_stop_words:\n",
    "    lexeme = nlp.vocab[stopword]\n",
    "    lexeme.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpCorpus = list(map(lambda doc: nlp(doc), corpus[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterWords(word):\n",
    "    return word.is_alpha and not word.is_stop\n",
    "\n",
    "def convertWords(word):\n",
    "    return word.lemma_.lower()\n",
    "\n",
    "def cleanDoc(doc):\n",
    "    return list(map(convertWords, filter(filterWords, doc)))\n",
    "\n",
    "cleanCorpus = list(map(lambda doc: cleanDoc(doc), nlpCorpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleanCorpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to mess around with these\n",
    "threshold = 1\n",
    "minCount = 1\n",
    "bigram = Phrases(cleanCorpus, min_count=minCount, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanBigramCorpus = [bigram[doc] for doc in cleanCorpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanBigramCorpus[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(cleanBigramCorpus)\n",
    "bow = [dictionary.doc2bow(doc) for doc in cleanBigramCorpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TfidfModel(bow)  # fit model\n",
    "vector = model[bow[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vector[:20])\n",
    "\n",
    "iterator = iter(dictionary.token2id.items())\n",
    "for i in range(20):\n",
    "    print(next(iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = LdaModel(bow, num_topics=10, id2word=dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
